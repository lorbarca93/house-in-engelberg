# System Architecture

## Overview

The Engelberg Property Investment Simulation is a comprehensive financial modeling system for co-ownership vacation rental investments. It combines deterministic base case analysis, sensitivity analysis, and probabilistic Monte Carlo simulation with a modern web-based dashboard.

## Architecture Diagram

```
+-------------------------------------------------------------+
|                     USER INTERFACE                           |
|  website/index.html (6,157+ lines)                          |
|  - State Management                                          |
|  - DataManager (JSON loading)                               |
|  - ChartRenderer (Plotly.js visualizations)                 |
|  - UIManager (UI controls & horizon sync)                   |
+----------------+--------------------------------------------+
                 | Fetch JSON
                 v
+-------------------------------------------------------------+
|                     DATA LAYER                               |
|  website/data/*.json (76+ files)                            |
|  - Base case analysis (12 files)                            |
|  - Sensitivity analyses (36 files: 3 types x 12 cases)      |
|  - Monte Carlo results (12 files)                           |
|  - Monte Carlo Sensitivity (12 files)                       |
|  - cases_index.json (case metadata)                         |
+----------------+--------------------------------------------+
                 | Generated by
                 v
+-------------------------------------------------------------+
|                  ANALYSIS LAYER                              |
|  engelberg/ package (6,551+ lines)                          |
|  +------------------------------------------------------+  |
|  | analysis.py (571+ lines)                             |  |
|  | - run_base_case_analysis()                           |  |
|  | - Orchestrates all analysis types                    |  |
|  | - Exports to JSON                                    |  |
|  +------------------------------------------------------+  |
|  +------------------------------------------------------+  |
|  | model_sensitivity.py (954+ lines)                    |  |
|  | - run_unified_sensitivity_analysis()                 |  |
|  | - Equity IRR, Cash-on-Cash, Monthly NCF metrics      |  |
|  | - 16 parameters x 3 scenarios (low/base/high)        |  |
|  +------------------------------------------------------+  |
|  +------------------------------------------------------+  |
|  | mc_sensitivity.py (435+ lines)                       |  |
|  | - run_monte_carlo_sensitivity_analysis()             |  |
|  | - NPV > 0 probability curves                         |  |
|  | - 6 parameters x 10 values x 1,000 sims              |  |
|  +------------------------------------------------------+  |
|  +------------------------------------------------------+  |
|  | monte_carlo.py (2,430+ lines)                        |  |
|  | - run_monte_carlo_simulation()                       |  |
|  | - Latin Hypercube Sampling                           |  |
|  | - Correlation modeling (Gaussian copula)             |  |
|  | - Time-varying parameters (AR(1))                    |  |
|  | - Event modeling (maintenance, shocks, refinancing)  |  |
|  | - Parallel processing                                |  |
|  +------------------------------------------------------+  |
|  +------------------------------------------------------+  |
|  | core.py (1,814+ lines)                               |  |
|  | - compute_annual_cash_flows()                        |  |
|  | - compute_15_year_projection()                       |  |
|  | - calculate_irrs_from_projection()                   |  |
|  | - apply_sensitivity()                                |  |
|  | - BaseCaseConfig dataclass                           |  |
|  +------------------------------------------------------+  |
+----------------+--------------------------------------------+
                 | Uses
                 v
+-------------------------------------------------------------+
|                  CONFIGURATION LAYER                         |
|  assumptions/ (12 JSON files)                               |
|  - assumptions.json (base case)                             |
|  - assumptions_*.json (scenario overrides)                  |
|  - Hierarchical: scenarios inherit from base               |
+-------------------------------------------------------------+

+-------------------------------------------------------------+
|                  CLI / AUTOMATION                            |
|  scripts/ (1,448+ lines total)                              |
|  - analyze.py: Run analyses for single case                 |
|  - generate_all_data.py: Batch generation for all cases     |
|  - validate_system.py: 403 automated checks                 |
+-------------------------------------------------------------+

+-------------------------------------------------------------+
|                  TESTING LAYER                               |
|  tests/ (154 tests)                                         |
|  - unit/: Core calculations, IRR, projections, seasonality  |
|  - integration/: End-to-end analysis workflows              |
|  - regression/: Known-value verification                    |
|  - fixtures/: Test configurations and data                  |
+-------------------------------------------------------------+
```

## Data Flow

### Base Case Analysis

```
1. Load assumptions.json
   v
2. Create BaseCaseConfig
   v
3. compute_annual_cash_flows(config)
   -> Returns Year 1 metrics (NOI, cash flow, tax savings, etc.)
   v
4. compute_15_year_projection(config)
   -> Returns 15-year projection with inflation, appreciation
   v
5. calculate_irrs_from_projection(projection)
   -> Returns Equity IRR, Project IRR, NPV, MOIC
   v
6. Export to {case}_base_case_analysis.json
   v
7. Dashboard loads and renders KPIs, charts, tables
```

### Sensitivity Analysis

```
1. Load base config
   v
2. Compute base metrics (IRR, CoC, NCF)
   v
3. For each of 16 parameters:
   a. Calculate low/high values (from factors)
   b. apply_sensitivity(base_config, param=low_value)
   c. Compute metric for low scenario
   d. apply_sensitivity(base_config, param=high_value)
   e. Compute metric for high scenario
   f. Calculate impact: |high - low|
   v
4. Sort by impact (descending)
   v
5. Export to {case}_sensitivity*.json
   v
6. Dashboard renders tornado charts
```

### Monte Carlo Simulation

```
1. Load base config
   v
2. Define probability distributions (23 stochastic parameters)
   v
3. Generate samples:
   - Latin Hypercube Sampling (stratified)
   - Apply correlations (Gaussian copula)
   -> Returns samples matrix [num_sims x num_params]
   v
4. For each simulation (parallel):
   a. Extract sampled values
   b. Generate time-varying series (inflation, appreciation)
   c. Generate events (maintenance, shocks, refinancing)
   d. Build modified config
   e. compute_annual_cash_flows(config)
   f. compute_15_year_projection(config, events, time_series)
   g. Calculate NPV and IRR
   v
5. Aggregate statistics (mean, median, percentiles, probabilities)
   v
6. Export to {case}_monte_carlo.json
   v
7. Dashboard renders distributions, CDFs, box plots
```

### Monte Carlo Sensitivity

```
1. Load base config
   v
2. For each of 6 parameters:
   a. Generate 10 evenly-spaced values across range
   b. For each value:
      - Fix parameter at that value
      - Run Monte Carlo (1,000 sims)
      - Extract NPV > 0 probability
   c. Calculate impact: max_prob - min_prob
   v
3. Rank parameters by impact
   v
4. Export to {case}_monte_carlo_sensitivity.json
   v
5. Dashboard renders probability curves
```

## Key Design Patterns

### 1. Configuration Immutability

- **Pattern**: Never mutate base config; create new configs with modifications
- **Implementation**: `apply_sensitivity()` returns new `BaseCaseConfig` instance
- **Benefit**: Thread-safe, predictable, testable

### 2. Hierarchical Configuration

- **Pattern**: Scenarios inherit from base assumptions.json, override only changed values
- **Implementation**: `load_base_case_config()` merges scenario overrides into base
- **Benefit**: Single source of truth, DRY principle, easy scenario creation

### 3. Lazy Data Loading

- **Pattern**: Dashboard loads JSON only when needed (not all at startup)
- **Implementation**: `DataManager.loadCaseData()` caches loaded data
- **Benefit**: Faster initial load, lower memory usage

### 4. Separation of Concerns

- **Pattern**: Clear separation between calculation (Python), data (JSON), presentation (JavaScript)
- **Benefit**: Can modify UI without touching calculations, easy to test

### 5. Defensive Programming

- **Pattern**: Extensive validation, error handling, type checking
- **Implementation**:
  - Specific exception types (no bare `except:`)
  - UTF-8 encoding on all file operations
  - Input validation with descriptive errors
  - 403 automated validation checks
- **Benefit**: Robust system, clear error messages, easier debugging

## Module Responsibilities

### engelberg/core.py

**Purpose**: Core financial calculation engine

**Key Functions**:
- `compute_annual_cash_flows()`: Year 1 cash flow calculations
- `compute_15_year_projection()`: Multi-year projections with inflation/appreciation
- `calculate_irrs_from_projection()`: IRR, NPV, MOIC calculations
- `apply_sensitivity()`: Configuration modification for sensitivity tests
- `load_base_case_config()`: Assumption loading and validation

**Dependencies**: None (pure calculations)

### engelberg/analysis.py

**Purpose**: Analysis orchestration and export

**Key Functions**:
- `run_base_case_analysis()`: Orchestrates base case workflow
- `export_base_case_to_json()`: Structured JSON export
- Imports and re-exports from sensitivity and Monte Carlo modules

**Dependencies**: core, model_sensitivity, mc_sensitivity, monte_carlo

### engelberg/model_sensitivity.py

**Purpose**: Deterministic sensitivity analysis

**Key Functions**:
- `run_unified_sensitivity_analysis()`: Main entry point for all 3 metrics
- Metric calculators: `calculate_equity_irr()`, `calculate_cash_on_cash()`, `calculate_monthly_ncf()`
- `test_parameter_sensitivity()`: Single parameter variation testing

**Dependencies**: core

### engelberg/monte_carlo.py

**Purpose**: Probabilistic Monte Carlo simulation

**Key Functions**:
- `run_monte_carlo_simulation()`: Main simulation orchestrator
- `latin_hypercube_sample()`: LHS sampling with correlations
- `generate_time_series()`: AR(1) mean-reverting series
- Event generators: maintenance, shocks, refinancing
- `calculate_statistics()`: Result aggregation

**Dependencies**: core, numpy, pandas, scipy

### engelberg/mc_sensitivity.py

**Purpose**: Monte Carlo-based sensitivity analysis

**Key Functions**:
- `run_monte_carlo_sensitivity_analysis()`: Parameter variation with Monte Carlo
- `generate_parameter_range()`: Evenly-spaced value generation

**Dependencies**: core, monte_carlo

## Frontend Architecture

### State Management

```javascript
const State = {
  currentCase: "base_case",
  currentAnalysis: "base_case",
  currentHorizon: 15,
  cases: [],
  data: {}  // Cache: {case_analysis: jsonData}
};
```

### Component Structure

```javascript
// DataManager: JSON loading and caching
DataManager = {
  loadCases() { /* Fetch cases_index.json */ },
  loadCaseData(caseName, analysisType) { /* Fetch with cache-busting */ }
};

// ChartRenderer: Plotly.js visualization
ChartRenderer = {
  renderBaseCase(data) { /* KPIs, tables, projections */ },
  renderSensitivity(data) { /* Tornado charts */ },
  renderSensitivityCoC(data) { /* CoC tornado */ },
  renderSensitivityNCF(data) { /* NCF tornado */ },
  renderMonteCarlo(data) { /* Distributions, CDFs, box plots */ },
  renderMonteCarloSensitivity(data) { /* Probability curves */ },
  renderWaterfall(data) { /* Cash flow bridge */ },
  renderScenarioComparison() { /* Multi-case comparison */ }
};

// UIManager: UI controls and visibility
UIManager = {
  syncHorizonOptions(availableKeys) { /* Populate dropdown */ },
  showHorizonBar() { /* Display horizon selector */ },
  hideHorizonBar() { /* Hide for Year-1 metrics */ }
};

// Controller: Event handling and orchestration
Controller = {
  init() { /* Setup event listeners */ },
  loadAnalysis(analysisType) { /* Sidebar navigation */ },
  rerenderCurrent() { /* Refresh current view */ }
};
```

### Event Flow

```
User selects case
  v
casesSelect.change event
  v
State.currentCase = newCase
  v
URL updated (?case=newCase)
  v
Controller.rerenderCurrent()
  v
DataManager.loadCaseData(case, analysis)
  v
ChartRenderer.render{AnalysisType}(data)
  v
UI updates with new charts/tables
```

## Testing Architecture

### Test Categories

```
tests/
+-- unit/
|   +-- test_core_calculations.py (46 tests)
|   |   - Annual cash flows
|   |   - Tax calculations
|   |   - Debt service
|   |   - Edge cases
|   +-- test_irr_calculations.py (16 tests)
|   |   - IRR binary search
|   |   - Edge cases (all positive/negative CF)
|   |   - Precision validation
|   +-- test_projections.py (35 tests)
|   |   - 15-year projection logic
|   |   - Inflation application
|   |   - Appreciation calculation
|   |   - Variable parameters
|   +-- test_seasonal_logic.py (18 tests)
|   |   - Seasonal rental calculations
|   |   - Occupancy distribution
|   |   - Weighted averages
|   +-- test_dataclasses.py (3 tests)
|       - Config validation
|       - Field constraints
+-- integration/
|   +-- test_base_case_analysis.py (15 tests)
|   |   - End-to-end base case workflow
|   |   - JSON export validation
|   +-- test_sensitivity_analysis.py (5 tests)
|   |   - Sensitivity workflow
|   |   - Multi-metric validation
|   +-- test_monte_carlo.py (3 tests)
|       - Monte Carlo simulation workflow
|       - Statistical properties
+-- regression/
    +-- test_known_values.py (1 test)
        - Verify against known good results
        - Prevent calculation drift
```

### Validation System

**scripts/validate_system.py** - 403 checks across 13 categories:

1. **File Structure** (20 checks): Required files and directories exist
2. **Python Modules** (15 checks): Imports resolve correctly
3. **Assumptions** (30 checks): JSON structure and required fields
4. **Cross-Dependencies** (25 checks): File references are valid
5. **Generated Data** (120 checks): All expected JSON files exist and valid
6. **Calculation Consistency** (40 checks): Cross-validation of calculations
7. **Output KPI Safety Ranges** (12 checks): Sanity ranges for key outputs
8. **Cross-Validation** (30 checks): Assumptions <-> Data consistency
9. **Sensitivity Analysis** (35 checks): Sensitivity structure and deltas
10. **Monte Carlo** (20 checks): Monte Carlo statistics and distributions
11. **Dashboard Components** (15 checks): Required HTML/JS elements
12. **Script Integration** (10 checks): Scripts run without errors
13. **E2E Consistency** (7 checks): End-to-end workflow validation

## Performance Characteristics

### Execution Times (Typical Desktop)

| Operation | Time | Simulations | Notes |
|-----------|------|-------------|-------|
| Base Case Analysis | ~0.5s | N/A | Single deterministic calculation |
| Model Sensitivity (all 3) | ~8s | 48 scenarios | 16 params x 3 scenarios x 3 metrics |
| Monte Carlo | ~15s | 1,000 | Latin Hypercube, parallel processing |
| Monte Carlo Sensitivity | ~200s | 60,000 | 6 params x 10 values x 1,000 sims |
| Full Generation (all cases) | ~4min | 858,000 | 12 cases x all analyses |
| System Validation | ~7s | N/A | 403 automated checks |

### Memory Usage

- **Base Case**: ~50 MB
- **Monte Carlo (1,000 sims)**: ~200 MB
- **Monte Carlo Sensitivity (60,000 sims)**: ~500 MB peak (processed in batches)

### Scalability

- **Cases**: Linear scaling (O(n) per case)
- **Monte Carlo sims**: Linear scaling with number of simulations
- **Parallel speedup**: 4-8x on multi-core systems
- **Dashboard**: Fast loading (<1s) due to lazy data loading

## Error Handling Strategy

### Python Backend

1. **Input Validation**: Validate assumptions before processing
2. **Specific Exceptions**: Never use bare `except:` clauses
3. **Graceful Degradation**: Fallback values for non-critical failures
4. **Logging**: Warning messages for debugging
5. **UTF-8 Encoding**: Explicit encoding on all file operations

### JavaScript Frontend

1. **Data Validation**: Check for required fields before rendering
2. **Try-Catch**: Wrap JSON parsing and fetch operations
3. **User-Friendly Errors**: Display helpful messages instead of blank screens
4. **Fallback UI**: Show "Loading..." or "No data available" states
5. **Console Logging**: Debug information in development

## Key Design Decisions

### Why Python Backend + JavaScript Frontend?

- **Python**: Excellent for numerical computing, data analysis, testing
- **JavaScript**: Excellent for interactive UIs, data visualization
- **JSON**: Universal interchange format, easy to debug

### Why Single-Page Dashboard?

- **User Experience**: Instant switching between analyses
- **Performance**: Lazy loading, client-side rendering
- **Simplicity**: No backend server required
- **Portability**: Can be served from any static file host

### Why Latin Hypercube Sampling?

- **Efficiency**: 2-3x more efficient than random sampling
- **Coverage**: Better exploration of parameter space
- **Accuracy**: More accurate statistics with fewer simulations

### Why Gaussian Copula?

- **Realism**: Preserves correlations while allowing different marginal distributions
- **Flexibility**: Can model any marginal distribution with any correlation structure
- **Accuracy**: Better represents real-world parameter relationships

## Extension Points

### Adding a New Analysis Type

1. Create analysis function in `engelberg/` package
2. Add JSON export logic
3. Update `scripts/generate_all_data.py` to include new analysis
4. Add renderer function in `website/index.html`
5. Add sidebar menu item
6. Add validation checks in `scripts/validate_system.py`

### Adding a New Scenario

1. Create `assumptions/assumptions_newcase.json` with overrides
2. Add case metadata (`_case_metadata` section)
3. Run `python scripts/generate_all_data.py`
4. New case automatically appears in dashboard dropdown

### Adding a New Metric

1. Add calculation function to `engelberg/core.py` or `engelberg/analysis.py`
2. Update `compute_annual_cash_flows()` or create new function
3. Add to JSON export
4. Update dashboard renderer to display new metric

## Technology Stack

### Backend

- **Python**: 3.8+
- **pandas**: Data manipulation and aggregation
- **numpy**: Numerical computing and sampling
- **scipy**: Statistical distributions and optimization
- **openpyxl**: Excel export (optional)
- **plotly**: Chart generation (for Excel/HTML exports)

### Frontend

- **Vanilla JavaScript**: No frameworks (simplicity, performance)
- **Plotly.js**: Interactive data visualization
- **Font Awesome**: Icons
- **CSS3**: Modern styling with CSS variables

### Development

- **pytest**: Testing framework
- **pytest-cov**: Code coverage analysis
- **black**: Code formatting (recommended)
- **pylint/flake8**: Code quality (recommended)

## Security Considerations

1. **No User Input**: Dashboard is read-only (no form submissions)
2. **No Eval**: No `eval()` or `exec()` in codebase
3. **File Operations**: Explicit encoding, no shell commands
4. **XSS Protection**: All data is JSON (not HTML injection)
5. **CORS**: Local file serving only (no external APIs)

## Future Enhancements

### Potential Improvements

1. **Type Hints**: Add Python type hints throughout codebase
2. **Interactive Sensitivity**: Allow users to adjust parameters in UI
3. **Custom Scenarios**: UI for creating new scenarios without editing JSON
4. **Export to Excel**: Export dashboard data directly from UI
5. **Comparison Mode**: Side-by-side chart comparison
6. **Mobile Optimization**: Enhanced mobile layouts
7. **Dark Mode**: Theme switching
8. **API Layer**: Optional REST API for programmatic access

### Performance Optimizations

1. **Caching**: Cache computation results to avoid recalculation
2. **Incremental Monte Carlo**: Add simulations to existing results
3. **Web Workers**: Run calculations in browser for interactive scenarios
4. **Compression**: Compress JSON data files
5. **Progressive Loading**: Load chart data on-demand as user scrolls

---

**Created**: February 2, 2026
**Purpose**: System architecture reference for the Engelberg analysis stack
**Status**: Reference Documentation
